package ac.biu.cs.nlp.protec.data;

import java.io.BufferedReader;
import java.io.FileNotFoundException;
import java.io.FileReader;
import java.io.IOException;

import java.util.Hashtable;
import java.util.LinkedList;
import java.util.List;
import java.util.Map;

import ac.biu.cs.nlp.protec.data.rep.FakePartOfSpeech;
import ac.biu.nlp.nlp.instruments.lemmatizer.Lemmatizer;
import ac.biu.nlp.nlp.instruments.lemmatizer.LemmatizerException;
import ac.biu.nlp.nlp.instruments.postagger.MaxentPosTagger;

import ac.biu.nlp.nlp.representation.PartOfSpeech;

import ac.biu.nlp.nlp.representation.UnsupportedPosTagStringException;


import edu.uci.ics.jung.graph.DirectedGraph;
import edu.uci.ics.jung.graph.DirectedSparseMultigraph;


public abstract class AbstractDataOrganizer implements DataOrganizer{

	protected boolean m_doFilterStopwords=false;
	protected String m_stopwordsFilename=null;
	protected String m_inputFile=null;	
	protected double m_stopwordMoreThanPercentThreshold=0;
	protected double m_stopwordLessThanPercentThreshold=0;
	
	protected List<String> m_stopWords=null;
	protected MaxentPosTagger m_posTagger=null;

	//	protected static final File gateRulesFile = new File("D:/Jars/GATE-3.1/plugins/Tools/resources/morph/default.rul");
	protected Lemmatizer m_lemmatizer;
	protected String m_gateRulesFilename;

	protected  Map<String, LinkedList<Integer>> m_docIdsByText = null;
	protected  Map<Integer, String> m_docTextById = null;	
	protected  Map<String, Map<Integer,Integer>> m_originalDocsByTerm = null;
	protected  Map<String, Map<Integer,Integer>> m_expandedDocsByTerm = null;
	protected  Map<String, LinkedList<Integer>> m_docsPerCluster = null;
	protected  Map<Integer, LinkedList<String>> m_clustersPerDoc = null;
	
	
	/**
	 * This map shows in how many different documents each term occurs (before expansion)
	 */
	protected  Map<String, Integer> m_termFrequenciesInCorpusBeforeExpansion = null;
	
	public Map<String,Integer> getTermFrequenciesBeforeExpansion(){
		return m_termFrequenciesInCorpusBeforeExpansion;
	}
	protected  DirectedGraph<String, Integer> m_initialTermGraph = new DirectedSparseMultigraph<String, Integer>();
	
	protected void setInputFile(String inputFile) {
		this.m_inputFile = inputFile;
	}


	public boolean isB_filterStopwords() {
		return m_doFilterStopwords;
	}



	public Map<Integer, ? extends List<String>> getGoldStandardClustersPerDoc() {
		return m_clustersPerDoc;
	}



	public Map<String, ? extends List<Integer>> getDocIdsByText() {
		return m_docIdsByText;
	}




	public Map<String, Map<Integer, Integer>> getDocsByTermBeforeExpansion() {
		return m_originalDocsByTerm;
	}



	public Map<String, ? extends List<Integer>> getDocsPerGoldStandardCluster() {
		return m_docsPerCluster;
	}



	public Map<Integer, String> getDocTextsById() {
		return m_docTextById;
	}



	public Map<String, Map<Integer, Integer>> getDocsByTermAfterExpansion() {
		return m_expandedDocsByTerm;
	}



	public String getGateRulesFilename() {
		return m_gateRulesFilename;
	}



	public DirectedGraph<String, Integer> getInitialTermGraph() {
		return m_initialTermGraph;
	}



	public String getInputFile() {
		return m_inputFile;
	}



	public Lemmatizer getLemmatizer() {
		return m_lemmatizer;
	}



	public MaxentPosTagger getPosTagger() {
		return m_posTagger;
	}


	public List<String> getStopWords() {
		return m_stopWords;
	}


	protected void updateOriginalDocsByTerm(String term, Integer docId, Integer count){
		// count - how many times the term is found in the document
		Map<Integer,Integer> docTermCounts;	
		if (m_originalDocsByTerm.containsKey(term)) docTermCounts=m_originalDocsByTerm.get(term);
		else docTermCounts = new Hashtable<Integer,Integer>();	
		
		if(!docTermCounts.containsKey(docId)) {
			docTermCounts.put(docId, count);
		}
		else{	
			docTermCounts.put(docId,docTermCounts.get(docId)+count);
		}
		m_originalDocsByTerm.put(term, docTermCounts);
		m_expandedDocsByTerm.put(term, docTermCounts);
		
		int termFreq=1; //termFreq shows in how many different docs this term occurs
		if (m_termFrequenciesInCorpusBeforeExpansion.containsKey(term)){
			termFreq+=m_termFrequenciesInCorpusBeforeExpansion.get(term);
		}
		m_termFrequenciesInCorpusBeforeExpansion.put(term, termFreq);
	}
	

	protected void updateExpandedDocsByTerm(String term, Integer docId, Integer count){
		// count - how many times the term is found in the document
		Map<Integer,Integer> docTermCounts;	
		if (m_expandedDocsByTerm.containsKey(term)) docTermCounts=m_expandedDocsByTerm.get(term);
		else docTermCounts = new Hashtable<Integer,Integer>();	
		
		if(!docTermCounts.containsKey(docId)) {
			docTermCounts.put(docId, count);
		}
		else{	
			docTermCounts.put(docId,docTermCounts.get(docId)+count);
		}
		m_expandedDocsByTerm.put(term, docTermCounts);
	}

	protected void loadStopwords(){
		if (m_doFilterStopwords){
			try {
				BufferedReader reader = new BufferedReader(new FileReader(m_stopwordsFilename));
				m_stopWords = new LinkedList<String>();
				String line = reader.readLine();	
				while(line != null) {
					m_stopWords.add(line.replace("\n", ""));
					line=reader.readLine();
				}
			} catch (FileNotFoundException e) {
				// TODO Auto-generated catch block
				e.printStackTrace();
			} catch (IOException e) {
				// TODO Auto-generated catch block
				e.printStackTrace();
			}			
		}
		else m_stopWords=null;
	}
	
	protected boolean isStopword(String term){
		if (m_stopWords.contains(term)) return true;
		if (term.toCharArray().length<2) return true;
		return false;
	}
	
/*	protected static boolean isValidPOS(char pos){
		if ((pos=='j')||(pos=='r')||(pos=='n')||(pos=='v')) return true;	
		else return false;
	}*/
	
	protected boolean isStopwordNgram(String ngram){
		boolean allTermsAreStopwords = true;
		for (String term : ngram.split(" ")){
			if (!isStopword(term)) {
				allTermsAreStopwords=false;
				break;
			}
		}
		
		if (allTermsAreStopwords) return true;
		
		// if ngram is found in 0 docs, it's a stopword
		int ngramFrequency=m_termFrequenciesInCorpusBeforeExpansion.get(ngram);
		if (ngramFrequency==0) return true;

		int docsNumber = m_docTextById.size();
		if(ngramFrequency>=docsNumber*m_stopwordMoreThanPercentThreshold) {
			if(ngramFrequency<=docsNumber*m_stopwordLessThanPercentThreshold){
				return true;
			}
		}

		
		return false;

	}
	
	protected void filterStowords(){
		
		for (String ngram : m_termFrequenciesInCorpusBeforeExpansion.keySet()){
			if (isStopwordNgram(ngram)){
				m_originalDocsByTerm.remove(ngram);
				m_expandedDocsByTerm.remove(ngram);
				m_initialTermGraph.removeVertex(ngram);
			}
		}
		System.out.println(m_originalDocsByTerm.size()+" different ngrams left after removing stopwords");
	}
	
/*	protected boolean isValidBigram(String bigram, char posA, char posB){
		// bigram is valid if 
		// 1) both its words are not stopwords
		// and 2) at least one of bigram's terms is an adverb (r), adjective (j), noun (n) or verb (v)		 
		if (isStopwordNgram(bigram)) return false;
		if ((posA=='j')||(posA=='r')||(posA=='n')||(posA=='v')) return true;
		if ((posB=='j')||(posB=='r')||(posB=='n')||(posB=='v')) return true;		
		return false; 
	}	*/
	
	protected String getLemma (String keyTokenLemma, char keyTokenPos) throws LemmatizerException, UnsupportedPosTagStringException{
		PartOfSpeech pos = new FakePartOfSpeech(String.valueOf(keyTokenPos));			
		m_lemmatizer.set(keyTokenLemma,pos);
		m_lemmatizer.process();
		return m_lemmatizer.getLemma();		
	}	
	
	protected String getLemma (String keyTokenLemma) throws LemmatizerException {
		m_lemmatizer.set(keyTokenLemma);
		m_lemmatizer.process();
		return m_lemmatizer.getLemma();			
	}	
	
}
